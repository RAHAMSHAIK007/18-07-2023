DAY-01: 
INTRO, SETUP AND PODS

CLUSTER COMPONENTS:

MANAGER:
1.API Server	: its used to commmunicate with cluster. takes input and gives op.
2.ETCD 		: its DB for cluster. stores complete infor of cluster.
3.Schedulers	: used to schedule pods on worker node, based on hardware resource of node.
4.Controllers-manager: communicate with controllers.
cloud control manager: cloud provider.
kube control manager: on prem.

we have 4 components in Worker Node.

WORKER:
1. Kubelet    : its an agent which communicates with master.
2. Kube-Proxy : it deal with networking.
3. Pod	      : it is group of containers.
4. Container  : 

SHORTCUT:
C: CLUSTER
N: NODE
P: POD
C: CONT
A: APP


MINIKUBE:

It is a tool used to setup single node cluster on K8's. 
It contains API Servers, ETDC database and container runtime
It helps you to containerized applications.
It is used for development, testing, and experimentation purposes on local. Here Master and worker runs on same machine
It is a platform Independent.
By default it will create one node only.
Installing Minikube is simple compared to other tools.

NOTE: But we dont implement this in real-time

REQUIRMENTS:
2 CPUs or more
2GB of free memory
20GB of free disk space
Internet connection
Container or virtual machine manager, such as: Docker.


SETUP:
sudo apt update -y
sudo apt upgrade -y
sudo apt install curl wget apt-transport-https -y
sudo curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
sudo mv minikube-linux-amd64 /usr/local/bin/minikube
sudo chmod +x /usr/local/bin/minikube
sudo minikube version
sudo curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
sudo curl -LO "https://dl.k8s.io/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl.sha256"
sudo echo "$(cat kubectl.sha256) kubectl" | sha256sum --check
sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
sudo minikube start --driver=docker --force

KUBECTL:
kubectl is the CLI which is used to interact with a Kubernetes cluster.
We can create, manage pods, services, deployments, and other resources.
The configuration of kubectl is in the $HOME/.kube directory.
The latest version is 1.28

PODS:
It is a smallest unit of deployment in K8's.
It is a group of containers.
Pods are ephemeral (short living objects)
Mostly we can use single container inside a pod but if we required, we can create multiple containers inside a same pod.
when we create a pod, containers inside pods can share the same network namespace, and can share the same storage volumes .
While creating pod, we must specify the image, along with any necessary configuration and resource limits.
K8's cannot communicate with containers, they can communicate with only pods.
 We can create this pod in two ways, 
1. Imperative(command) 
2. Declarative (Manifest file)


commands:
kubectl run pod1 --image hpakala53/paytmtrain:latest
kubectl get pods/pod/po
kubectl get pod -o wide
kubectl describe pod pod1 
kubectl delete pod pod1 

MANIFEST:
vim abc.yml

apiVersion: v1
kind: Pod
metadata:
  name: pod1
spec:
  containers:
    - image: hpakala53/paytmtrain:latest
      name: cont1

kubectl create -f abc.yml

kubectl get pods/pod/po
kubectl get pod -o wide
kubectl describe pod pod1 
kubectl delete pod pod1 

Note: if we delete the pod we cant retrive the pod.
so creating single pod is not a good practise in real time.
single pod will get more and more load.
so we need to create more than one pod.

REPLICASET:

HISTORY:
  1  sudo apt update -y
    2  sudo apt upgrade -y
    3  sudo apt install curl wget apt-transport-https -y
    4  sudo curl -fsSL https://get.docker.com -o get-docker.sh
    5  ll
    6  sh get-docker.sh
    7  cat get-docker.sh
    8  sudo curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
    9  ll
   10  sudo mv minikube-linux-amd64 /usr/local/bin/minikube
   11  chmod +x /usr/local/bin/minikube
   12  minikube version
   13  sudo curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
   14  sudo curl -LO "https://dl.k8s.io/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl.sha256"
   15  sudo echo "$(cat kubectl.sha256) kubectl" | sha256sum --check
   16  sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
   17  sudo minikube start --driver=docker --force
   18  minikube status
   19  kubectl run pod pod1 --image venkatesh1826/paytmmovies:latest
   20  kubectl get pod
   21  kubectl delete pod pod
   22  kubectl run pod1 --image venkatesh1826/paytmmovies:latest
   23  kubectl get pods
   24  kubectl get pod
   25  kubectl get po
   26  kubectl get po -o wide
   27  kubectl describe pod pod1
   28  kubectl delete pod pod1
   29  vim abc.yml
   30  cat abc.yml
   31  vim def.yml
   32  cat abc.yml
   33  cat def.yml
   34  rm -rf abc.yml
   35  kubectl create -f def.yml
   36  kubectl get po
   37  kubectl get po -o wide
   38  kubectl describe pod pod1
   39  kubectl delete pod pod1
   40  history
===========================================
DAY-02: 18-10-2023
REPLICASET, DEPLOYMENT & SCALING

REPLICASET:
it will create replicas of same pod.
we can use same application with multiple pods.
even if one pod is deleted automaticallly it will create another pod.
it has self healing.
depends on requirment we can scale the pods.

LABELS: used to assing for pods to maintain them as single unit.

kubectl api-resources

vim abc.yml

apiVersion: apps/v1
kind: ReplicaSet
metadata:
  labels:
    app: train
  name: train-rs
spec:
  replicas: 3
  selector:
    matchLabels:
      app: train
  template:
    metadata:
      labels:
        app: train
    spec:
      containers:
      - name: cont1
        image: hpakala53/paytmtrain:latest

kubectl create -f abc.yml

kubectl get rs
kubectl get po
kubectl describe rs train-rs
kubectl delete pod pod-name 
kubectl get pod -l app=train

kubectl scale rs/train-rs --replicas=10
kubectl scale rs/train-rs --replicas=5
LIFO: last pod will be deleted first 
kubectl delete rs train-rs

kubectl edit rs/train-rs -- > go and update image
it will update on rs  : kubectl describe rs train-rs
but it wont update on pods : kubectl describe pod

DRAWBACKS:
it will not update the images.
we cant do rolling and rollback.

DEPLOYMENT:
deployment will do all activites like RS.
it can also do  rolling and rollback of app.
its higher level k8s object.

deployment -- > replicaset -- > pod

apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: train
  name: train-deploy
spec:
  replicas: 3
  selector:
    matchLabels:
      app: train
  template:
    metadata:
      labels:
        app: train
    spec:
      containers:
      - name: cont1
        image: hpakala53/paytmtrain:latest


kubectl get deploy
kubectl get po
kubectl describe deploy train-deploy
kubectl get pod pod-name 

kubectl edit rs/train-rs -- > go and update image

kubectl scale deploy/train-deploy --replicas=10
kubectl scale deploy/train-deploy --replicas=5
LIFO: last pod will be deleted first 
kubectl delete deploy train-deploy

HISTORY:
 1  vim minikube.sh
    2  sh minikube.sh
    3  vim abc.yml
    4  vim abc.yml
    5  kubectl create -f abc.yml
    6  kubectl get po
    7  kubectl get po -o wide
    8  kubectl describe pod pod1
    9  kubectl delete pod pod1
   10  kubectl api-resources
   11  vim abc.yml
   12  kubectl create -f abc.yml
   13  cat abc.yml
   14  vim abc.yml
   15  cat abc.yml
   16  kubectl create -f abc.yml
   17  vim abc.yml
   18  kubectl create -f abc.yml
   19  vim abc.yml
   20  kubectl create -f abc.yml
   21  kubectl get rs
   22  kubectl get po
   23  kubectl get po --show-labels
   24  kubectl delete pod train-rs-szdkb
   25  kubectl get po
   26  kubectl delete pod train-rs-n8x42
   27  kubectl get po
   28  kubectl get po --show-labels
   29  kubectl get rs
   30  kubectl get rs -o wide
   31  kubectl describe rs train-rs
   32  kubectl get po
   33  kubectl scale rs/train-rs --replicas=10
   34  kubectl get po
   35  kubectl scale rs/train-rs --replicas=5
   36  kubectl get po
   37  kubectl scale rs/train-rs --replicas=3
   38  kubectl get po
   39  kubectl get rs
   40  kubectl describe rs train-rs
   41  kubectl describe pod
   42  kubectl edit rs/train-rs
   43  kubectl describe rs train-rs
   44  kubectl describe pod
   45  kubectl get po
   46  kubectl delete rs train-rs
   47  vim abc.yml
   48  kubectl create -f abc.yml
   49  kubectl get deploy
   50  kubectl get rs
   51  kubectl get po
   52  kubectl scale deploy/train-rs --replicas=10\
   53  kubectl get po
   54  kubectl scale deploy/train-rs --replicas=3
   55  kubectl get po
   56  kubectl delete pod train-rs-54bfbb8cc9-ddb2m
   57  kubectl get po
   58  kubectl edit rs/train-rs
   59  kubectl edit deploy/train-rs
   60  kubectl get po
   61  kubectl describe po
   62  kubectl edit deploy/train-rs
   63  kubectl get po
   64  kubectl describe po
   65  history
==========================================================
DAY-03: 19-10-2023
KOPS, ADMIN ACTIVITIES & KUBECOLRO

KOPS:
it is used to create multi node cluster.
it will have master and workers.
its free and open source tool.
its platfrom independent.
it will make cluster creation automatically.
currently it will support for AWS and GCP (others are in Beta stage)

ADVANTAGES:
automate infra creation.
supports homegenius and hetrogenius clusters.
cluster add-on.
save time and work.
generates terraform and CFT templates.

INFRA: resources used to run our application on cloud.
ex: Ec2, Alb, Vpc, Asg ----

MAUNAL METHOD:

STEP-1: CREATE IAM USER AND ATTACH TO EC2
aws configure -- > provide the details

STEP-2: INSTALL KUBECTL AND KOPS
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
wget https://github.com/kubernetes/kops/releases/download/v1.25.0/kops-linux-amd64
chmod +x kops-linux-amd64 kubectl
mv kubectl /usr/local/bin/kubectl
mv kops-linux-amd64 /usr/local/bin/kops

#vim .bashrc
#export PATH=$PATH:/usr/local/bin/
#source .bashrc

STEP-3: CREATE A BUCKET TO STORE CLUSTER INFO
aws s3api create-bucket --bucket ccitdevops20233.k8s.local --region us-east-1 
aws s3api put-bucket-versioning --bucket ccitdevops20233.k8s.local --region us-east-1 --versioning-configuration Status=Enabled
export KOPS_STATE_STORE=s3://ccitdevops20233.k8s.local

SETP-4: CREATE A CLUSTER AND RUN
kops create cluster --name rahams.k8s.local --zones us-east-1a --master-count=1 --master-size t2.medium --node-count=2 --node-size t2.micro
kops update cluster --name rahams.k8s.local --yes --admin


AUTOMATED SCRIPT:
SETUPS:

#vim .bashrc
#export PATH=$PATH:/usr/local/bin/
#source .bashrc


#! /bin/bash
aws configure
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
wget https://github.com/kubernetes/kops/releases/download/v1.25.0/kops-linux-amd64
chmod +x kops-linux-amd64 kubectl
mv kubectl /usr/local/bin/kubectl
mv kops-linux-amd64 /usr/local/bin/kops

aws s3api create-bucket --bucket ccitdevops20233.k8s.local --region us-east-1 
aws s3api put-bucket-versioning --bucket ccitdevops20233.k8s.local --region us-east-1 --versioning-configuration Status=Enabled
export KOPS_STATE_STORE=s3://ccitdevops20233.k8s.local
kops create cluster --name rahams.k8s.local --zones us-east-1a --master-count=1 --master-size t2.medium --node-count=2 --node-size t2.micro
kops update cluster --name rahams.k8s.local --yes --admin


Suggestions:
 * list clusters with: kops get cluster
 * edit this cluster with: kops edit cluster ccitdevops20233.k8s.local
 * edit your node instance group: kops edit ig --name=ccitdevops20233.k8s.local nodes-us-east-1a
 * edit your master instance group: kops edit ig --name=ccitdevops20233.k8s.local master-us-east-1a


ADMIN ACTIVITES:
kops edit ig --name=ccitdevops2023.k8s.local nodes-us-east-1a
kops update cluster --name rahams.k8s.local --yes --admin
kops rolling-update cluster --yes

kops edit ig --name=ccitdevops2023.k8s.local master-us-east-1a
kops update cluster --name rahams.k8s.local --yes --admin
kops rolling-update cluster --yes

TO DELETE CLUSTER:
kops delete cluster --name rahams.k8s.local --yes 

KOPS commands are used for cluster activites.
KUBECTL commands are used for resource activites.


KUBECOLOR:

wget https://github.com/hidetatz/kubecolor/releases/download/v0.0.25/kubecolor_0.0.25_Linux_x86_64.tar.gz
tar -zxvf kubecolor_0.0.25_Linux_x86_64.tar.gz
./kubecolor
chmod +x kubecolor
mv kubecolor /usr/local/bin/
kubecolor get po

HISTORY:
 1  aws configure
    2  curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
    3  wget https://github.com/kubernetes/kops/releases/download/v1.25.0/kops-linux-amd64
    4  chmod +x kops-linux-amd64 kubectl
    5  mv kubectl /usr/local/bin/kubectl
    6  mv kops-linux-amd64 /usr/local/bin/kops
    7  kubectl version
    8  kops version
    9  vim .bashrc
   10  source .bashrc
   11  kubectl version
   12  kops version
   13  ll -al
   14  aws s3api create-bucket --bucket ccitdevops2023.k8s.local --region us-east-1
   15  aws s3api create-bucket --bucket ccitdevops20233.k8s.local --region us-east-1
   16  aws s3api put-bucket-versioning --bucket ccitdevops20233.k8s.local --region us-east-1                                                                                                                                           --versioning-configuration Status=Enabled
   17  export KOPS_STATE_STORE=s3://ccitdevops20233.k8s.local
   18  kops create cluster --name rahams.k8s.local --zones us-east-1a --master-count=1 --mas                                                                                                                                          ter-size t2.medium --node-count=2 --node-size t2.micro
   19  kops update cluster --name rahams.k8s.local --yes --admin
   20   kops validate cluster --wait 10m
   21  kops get cluster
   22  kubectl get no
   23  vim abc.yml
   24  kubectl create -f abc.yml
   25  kubectl get po
   26  kubectl get po -o wide
   27  kops edit ig --name=rahams.k8s.local nodes-us-east-1a
   28  kops update cluster --name rahams.k8s.local --yes --admin
   29  kops rolling-update cluster
   30  kubectl get no
   31  kops edit ig --name=rahams.k8s.local nodes-us-east-1a
   32  kops update cluster --name rahams.k8s.local --yes --admin
   33  kops rolling-update cluster
   34  kops edit ig --name=rahams.k8s.local master-us-east-1a
   35  kops update cluster --name rahams.k8s.local --yes --admin
   36  kops rolling-update cluster
   37  kubectl get po -o wide
   38  wget https://github.com/hidetatz/kubecolor/releases/download/v0.0.25/kubecolor_0.0.25                                                                                                                                          _Linux_x86_64.tar.gz
   39  tar -zxvf kubecolor_0.0.25_Linux_x86_64.tar.gz
   40  ./kubecolor
   41  chmod +x kubecolor
   42  mv kubecolor /usr/local/bin/
   43  kubecolor get po
   49  kops delete cluster --name rahams.k8s.local --yes
   50  history
